{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa661ea9a7948cc8f6fff49cdde6062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 09:28:08 INFO: Downloading default packages for language: id (Indonesian)...\n",
      "2022-05-30 09:28:08 INFO: File exists: /home/lan666as/stanza_resources/id/default.zip.\n",
      "2022-05-30 09:28:10 INFO: Finished downloading models and saved to /home/lan666as/stanza_resources.\n",
      "2022-05-30 09:28:11 INFO: Loading these models for language: id (Indonesian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "=======================\n",
      "\n",
      "2022-05-30 09:28:11 INFO: Use device: gpu\n",
      "2022-05-30 09:28:11 INFO: Loading: tokenize\n",
      "2022-05-30 09:28:16 INFO: Loading: pos\n",
      "2022-05-30 09:28:16 INFO: Loading: lemma\n",
      "2022-05-30 09:28:16 INFO: Loading: depparse\n",
      "2022-05-30 09:28:17 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from commons import NLPSingleton\n",
    "\n",
    "nlp = NLPSingleton(\"id\").nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koreksi Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rules\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "for i, aturan in enumerate(rules.aturan_tata_bahasa):\n",
    "    # matcher.add(f\"ATB{i:05d}\", [aturan[\"pola\"],], on_match = aturan[\"koreksi\"]) #if \"koreksi\" in aturan else None)\n",
    "    matcher.add(aturan[\"kode\"], [aturan[\"pola\"],], on_match = aturan[\"koreksi\"]) #if \"koreksi\" in aturan else None)\n",
    "\n",
    "for i, aturan in enumerate(rules.aturan_tata_tulis):\n",
    "    # matcher.add(f\"ATB{i:05d}\", [aturan[\"pola\"],], on_match = aturan[\"koreksi\"]) #if \"koreksi\" in aturan else None)\n",
    "    matcher.add(aturan[\"kode\"], [aturan[\"pola\"],], on_match = aturan[\"koreksi\"]) #if \"koreksi\" in aturan else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dia dia PRON PS3 nsubj Xxx True True Number=Sing|Person=3|PronType=Prs True\n",
      "sedang sedang ADV D-- advmod xxxx True True  False\n",
      "memakan menmakan VERB VSA root xxxx True False Number=Sing|Voice=Act False\n",
      "saya saya PRON PS1 obj xxxx True True Number=Sing|Person=1|Polite=Form|PronType=Prs False\n",
      "apel apel NOUN NSD compound xxxx True False Number=Sing False\n",
      ". . PUNCT Z-- punct . False False  False\n",
      "pada pada ADP R-- case xxxx True True  True\n",
      "saat saat NOUN NSD obl xxxx True True Number=Sing False\n",
      "yang yang PRON S-- nsubj xxxx True True PronType=Rel False\n",
      "bersamaan bersamaan ADJ VSA amod xxxx True False Number=Sing|Voice=Act False\n",
      ", , PUNCT Z-- punct , False False  False\n",
      "adik adik NOUN NSD nsubj xxxx True False Number=Sing False\n",
      "menaruh mentaruh VERB VSA root xxxx True False Number=Sing|Voice=Act False\n",
      "buku buku NOUN NSD obj xxxx True False Number=Sing False\n",
      "merah merah ADJ ASP amod xxxx True False Degree=Pos|Number=Sing False\n",
      "dikantor dikantor NOUN VSP compound xxxx True False Number=Sing|Voice=Pass False\n",
      ", , PUNCT Z-- punct , False False  False\n",
      "diatas diatas ADP VSP case xxxx True False Number=Sing|Voice=Pass False\n",
      ", , PUNCT Z-- punct , False False  False\n",
      "dikota dikota NOUN NSD conj xxxx True False Number=Sing False\n",
      ", , PUNCT Z-- punct , False False  False\n",
      "diyogyakarta diyogyakarta NOUN X-- conj xxxx True False  False\n",
      ", , PUNCT Z-- punct , False False  False\n",
      "disungai disungai NOUN VSP conj xxxx True False Number=Sing|Voice=Pass False\n",
      ", , PUNCT Z-- punct , False False  False\n",
      "dimeja dimeja NOUN NSD conj xxxx True False Number=Sing False\n",
      "dan dan CCONJ H-- cc xxx True True  False\n",
      "dilayani dilayani VERB VSP conj xxxx True False Number=Sing|Voice=Pass False\n",
      ". . PUNCT Z-- punct . False False  False\n"
     ]
    }
   ],
   "source": [
    "# text = \"Kamu sedang makan apa? Memakan saya apel, kemana ia pergi dengan mobil otomatis itu? Adik menaruh buku merah dikantor, dipantai, dan dilayani\"\n",
    "text = \"Dia sedang memakan saya apel. pada saat yang bersamaan, adik menaruh buku merah dikantor, diatas, dikota, diyogyakarta, disungai, dimeja dan dilayani.\"\n",
    "# text = \"Aku sedang makan ikan. Ibu membelinya dari pasar.\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop, token.morph, token.is_sent_start)\n",
    "# for token in doc:\n",
    "#     print(f'{token.text:15} {token.pos_:10} {token.tag_:5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[memakan, saya, apel] -> [memakan, apel, saya]\n",
      "pada -> Pada\n",
      "dikantor ->  di kantor\n",
      "diatas ->  di atas\n",
      "dikota ->  di kota\n",
      "diyogyakarta ->  di yogyakarta\n",
      "disungai ->  di sungai\n",
      "dimeja ->  di meja\n",
      "[disungai, ,, dimeja, dan, dilayani] -> disungai, dimeja, dan dilayani\n",
      "1778349984811097675 KATA_KERJA_KATA_GANTI_KATA_BENDA 2 5 memakan saya apel\n",
      "4327641321007661059 HURUF_KAPITAL_AWAL_KALIMAT 6 7 pada\n",
      "767140364939751820 KATA_DEPAN_DI_DIPISAH 15 16 dikantor\n",
      "767140364939751820 KATA_DEPAN_DI_DIPISAH 17 18 diatas\n",
      "767140364939751820 KATA_DEPAN_DI_DIPISAH 19 20 dikota\n",
      "767140364939751820 KATA_DEPAN_DI_DIPISAH 21 22 diyogyakarta\n",
      "767140364939751820 KATA_DEPAN_DI_DIPISAH 23 24 disungai\n",
      "767140364939751820 KATA_DEPAN_DI_DIPISAH 25 26 dimeja\n",
      "18005231957729139259 KOMA_SEBELUM_DAN 23 28 disungai, dimeja dan dilayani\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dia sedang memakan saya apel.\n",
      "pada saat yang bersamaan, adik menaruh buku merah dikantor, diatas, dikota, diyogyakarta, disungai, dimeja dan dilayani.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0f2a3e58260a74740d6ed31560668974a8d751c98e07170dead6bbfa28ca03d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('senior-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
